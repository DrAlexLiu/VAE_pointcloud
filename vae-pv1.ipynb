{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import trimesh\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "from copy import copy\n",
    "import h5py\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /mnt/fsx-home/xingchenliu/.cache/torch_extensions/py38_cu116 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /mnt/fsx-home/xingchenliu/.cache/torch_extensions/py38_cu116/_pvcnn_backend/build.ninja...\n",
      "Building extension module _pvcnn_backend...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module _pvcnn_backend...\n"
     ]
    }
   ],
   "source": [
    "from models.pvcnn2 import Voxelization\n",
    "from third_party.pvcnn.functional.devoxelization import trilinear_devoxelize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borrow from https://github.com/luost26/diffusion-point-cloud/blob/1e30d48d018820fbc7c67c8b3190215bd41878e4/utils/dataset.py\n",
    "\n",
    "synsetid_to_cate = {\n",
    "    '02691156': 'airplane', '02773838': 'bag', '02801938': 'basket',\n",
    "    '02808440': 'bathtub', '02818832': 'bed', '02828884': 'bench',\n",
    "    '02876657': 'bottle', '02880940': 'bowl', '02924116': 'bus',\n",
    "    '02933112': 'cabinet', '02747177': 'can', '02942699': 'camera',\n",
    "    '02954340': 'cap', '02958343': 'car', '03001627': 'chair',\n",
    "    '03046257': 'clock', '03207941': 'dishwasher', '03211117': 'monitor',\n",
    "    '04379243': 'table', '04401088': 'telephone', '02946921': 'tin_can',\n",
    "    '04460130': 'tower', '04468005': 'train', '03085013': 'keyboard',\n",
    "    '03261776': 'earphone', '03325088': 'faucet', '03337140': 'file',\n",
    "    '03467517': 'guitar', '03513137': 'helmet', '03593526': 'jar',\n",
    "    '03624134': 'knife', '03636649': 'lamp', '03642806': 'laptop',\n",
    "    '03691459': 'speaker', '03710193': 'mailbox', '03759954': 'microphone',\n",
    "    '03761084': 'microwave', '03790512': 'motorcycle', '03797390': 'mug',\n",
    "    '03928116': 'piano', '03938244': 'pillow', '03948459': 'pistol',\n",
    "    '03991062': 'pot', '04004475': 'printer', '04074963': 'remote_control',\n",
    "    '04090263': 'rifle', '04099429': 'rocket', '04225987': 'skateboard',\n",
    "    '04256520': 'sofa', '04330267': 'stove', '04530566': 'vessel',\n",
    "    '04554684': 'washer', '02992529': 'cellphone',\n",
    "    '02843684': 'birdhouse', '02871439': 'bookshelf',\n",
    "    # '02858304': 'boat', no boat in our dataset, merged into vessels\n",
    "    # '02834778': 'bicycle', not in our taxonomy\n",
    "}\n",
    "cate_to_synsetid = {v: k for k, v in synsetid_to_cate.items()}\n",
    "\n",
    "\n",
    "class ShapeNetCore(Dataset):\n",
    "\n",
    "    GRAVITATIONAL_AXIS = 1\n",
    "    \n",
    "    def __init__(self, path, cates, split, scale_mode, transform=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(cates, list), '`cates` must be a list of cate names.'\n",
    "        assert split in ('train', 'val', 'test')\n",
    "        assert scale_mode is None or scale_mode in ('global_unit', 'shape_unit', 'shape_bbox', 'shape_half', 'shape_34')\n",
    "        self.path = path\n",
    "        if 'all' in cates:\n",
    "            cates = cate_to_synsetid.keys()\n",
    "        self.cate_synsetids = [cate_to_synsetid[s] for s in cates]\n",
    "        self.cate_synsetids.sort()\n",
    "        self.split = split\n",
    "        self.scale_mode = scale_mode\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pointclouds = []\n",
    "        self.stats = None\n",
    "\n",
    "        self.get_statistics()\n",
    "        self.load()\n",
    "\n",
    "    def get_statistics(self):\n",
    "\n",
    "        basename = os.path.basename(self.path)\n",
    "        dsetname = basename[:basename.rfind('.')]\n",
    "        stats_dir = os.path.join(os.path.dirname(self.path), dsetname + '_stats')\n",
    "        os.makedirs(stats_dir, exist_ok=True)\n",
    "\n",
    "        if len(self.cate_synsetids) == len(cate_to_synsetid):\n",
    "            stats_save_path = os.path.join(stats_dir, 'stats_all.pt')\n",
    "        else:\n",
    "            stats_save_path = os.path.join(stats_dir, 'stats_' + '_'.join(self.cate_synsetids) + '.pt')\n",
    "        if os.path.exists(stats_save_path):\n",
    "            self.stats = torch.load(stats_save_path)\n",
    "            return self.stats\n",
    "\n",
    "        with h5py.File(self.path, 'r') as f:\n",
    "            pointclouds = []\n",
    "            for synsetid in self.cate_synsetids:\n",
    "                for split in ('train', 'val', 'test'):\n",
    "                    pointclouds.append(torch.from_numpy(f[synsetid][split][...]))\n",
    "\n",
    "        all_points = torch.cat(pointclouds, dim=0) # (B, N, 3)\n",
    "        B, N, _ = all_points.size()\n",
    "        mean = all_points.view(B*N, -1).mean(dim=0) # (1, 3)\n",
    "        std = all_points.view(-1).std(dim=0)        # (1, )\n",
    "\n",
    "        self.stats = {'mean': mean, 'std': std}\n",
    "        torch.save(self.stats, stats_save_path)\n",
    "        return self.stats\n",
    "\n",
    "    def load(self):\n",
    "\n",
    "        def _enumerate_pointclouds(f):\n",
    "            for synsetid in self.cate_synsetids:\n",
    "                cate_name = synsetid_to_cate[synsetid]\n",
    "                for j, pc in enumerate(f[synsetid][self.split]):\n",
    "                    yield torch.from_numpy(pc), j, cate_name\n",
    "        \n",
    "        with h5py.File(self.path, mode='r') as f:\n",
    "            for pc, pc_id, cate_name in _enumerate_pointclouds(f):\n",
    "\n",
    "                if self.scale_mode == 'global_unit':\n",
    "                    shift = pc.mean(dim=0).reshape(1, 3)\n",
    "                    scale = self.stats['std'].reshape(1, 1)\n",
    "                elif self.scale_mode == 'shape_unit':\n",
    "                    shift = pc.mean(dim=0).reshape(1, 3)\n",
    "                    scale = pc.flatten().std().reshape(1, 1)\n",
    "                elif self.scale_mode == 'shape_half':\n",
    "                    shift = pc.mean(dim=0).reshape(1, 3)\n",
    "                    scale = pc.flatten().std().reshape(1, 1) / (0.5)\n",
    "                elif self.scale_mode == 'shape_34':\n",
    "                    shift = pc.mean(dim=0).reshape(1, 3)\n",
    "                    scale = pc.flatten().std().reshape(1, 1) / (0.75)\n",
    "                elif self.scale_mode == 'shape_bbox':\n",
    "                    pc_max, _ = pc.max(dim=0, keepdim=True) # (1, 3)\n",
    "                    pc_min, _ = pc.min(dim=0, keepdim=True) # (1, 3)\n",
    "                    shift = ((pc_min + pc_max) / 2).view(1, 3)\n",
    "                    scale = (pc_max - pc_min).max().reshape(1, 1) / 2\n",
    "                else:\n",
    "                    shift = torch.zeros([1, 3])\n",
    "                    scale = torch.ones([1, 1])\n",
    "\n",
    "                pc = (pc - shift) / scale\n",
    "\n",
    "                self.pointclouds.append({\n",
    "                    'pointcloud': pc,\n",
    "                    'cate': cate_name,\n",
    "                    'id': pc_id,\n",
    "                    'shift': shift,\n",
    "                    'scale': scale\n",
    "                })\n",
    "\n",
    "        # Deterministically shuffle the dataset\n",
    "        self.pointclouds.sort(key=lambda data: data['id'], reverse=False)\n",
    "        random.Random(2020).shuffle(self.pointclouds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pointclouds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = {k:v.clone() if isinstance(v, torch.Tensor) else copy(v) for k, v in self.pointclouds[idx].items()}\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/luost26/diffusion-point-cloud/blob/1e30d48d018820fbc7c67c8b3190215bd41878e4/utils/data.py\n",
    "def get_train_val_test_datasets(dataset, train_ratio, val_ratio):\n",
    "    assert (train_ratio + val_ratio) <= 1\n",
    "    train_size = int(len(dataset) * train_ratio)\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "def get_train_val_test_loaders(dataset, train_ratio, val_ratio, train_batch_size, val_test_batch_size, num_workers):\n",
    "    train_set, val_set, test_set = get_train_val_test_datasets(dataset, train_ratio, val_ratio)\n",
    "\n",
    "    train_loader = DataLoader(train_set, train_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_set, val_test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_set, val_test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def get_data_iterator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, data in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "def get_train_val_test_datasets(dataset, train_ratio, val_ratio):\n",
    "    assert (train_ratio + val_ratio) <= 1\n",
    "    train_size = int(len(dataset) * train_ratio)\n",
    "    val_size = int(len(dataset) * val_ratio)\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "def get_train_val_test_loaders(dataset, train_ratio, val_ratio, train_batch_size, val_test_batch_size, num_workers):\n",
    "    train_set, val_set, test_set = get_train_val_test_datasets(dataset, train_ratio, val_ratio)\n",
    "\n",
    "    train_loader = DataLoader(train_set, train_batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_set, val_test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_set, val_test_batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def get_data_iterator(iterable):\n",
    "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
    "        for i, data in enumerate(inf_generator(train_loader)):\n",
    "    \"\"\"\n",
    "    iterator = iterable.__iter__()\n",
    "    while True:\n",
    "        try:\n",
    "            yield iterator.__next__()\n",
    "        except StopIteration:\n",
    "            iterator = iterable.__iter__()\n",
    "\n",
    "# If you want the infinite loop, use get_data_iterator instead:\n",
    "# train_iter = get_data_iterator(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_pointcloud(points, title=\"\"):\n",
    "    \"\"\"Visualize a single point cloud.\"\"\"\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=5)\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_dataset(dataset, num_samples=5):\n",
    "    \"\"\"Visualize random samples from the dataset.\"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    for idx in indices:\n",
    "        sample = dataset[idx]\n",
    "        points = sample['pointcloud'].numpy()\n",
    "        title = sample['cate']\n",
    "        visualize_pointcloud(points, title=title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalVoxelNetEncoder(nn.Module):\n",
    "    def __init__(self, num_points=2048, latent_size=256, resolution=32, normalize=True, eps=1e-8):\n",
    "        super(VariationalVoxelNetEncoder, self).__init__()\n",
    "\n",
    "        # Voxelization layer\n",
    "        self.voxelizer = Voxelization(resolution, normalize, eps)\n",
    "\n",
    "        # Voxel convolution layers\n",
    "        self.voxel_conv1 = nn.Conv3d(1, 64, 3, stride=2, padding=1)  # assuming single channel voxel input\n",
    "        self.voxel_conv2 = nn.Conv3d(64, 128, 3, stride=2, padding=1)\n",
    "        self.voxel_conv3 = nn.Conv3d(128, 256, 3, stride=2, padding=1)\n",
    "\n",
    "        # Set abstraction layers (from PVCNN's sa_blocks)\n",
    "        self.sa_blocks = [\n",
    "            ((32, 2, 32), (1024, 0.1, 32, (32, 64))),\n",
    "            ((64, 3, 16), (256, 0.2, 32, (64, 128))),\n",
    "            ((128, 3, 8), (64, 0.4, 32, (128, 256))),\n",
    "            (None, (16, 0.8, 32, (128, 128, 128)))\n",
    "        ]\n",
    "        self.sa_layers = nn.ModuleList([create_sa_module(config) for config in self.sa_blocks])\n",
    "\n",
    "        # Fully connected layers to produce mu, logvar\n",
    "        self.fc_mu = nn.Linear(256, latent_size)  # adjusted based on last SA layer\n",
    "        self.fc_logvar = nn.Linear(256, latent_size)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming x has shape [B, D, N]\n",
    "        features = x[:, :-3, :]\n",
    "        coords = x[:, -3:, :]\n",
    "\n",
    "        # Voxelization\n",
    "        voxelized_features, norm_coords = self.voxelizer(features, coords)\n",
    "\n",
    "        # Voxel convolution layers\n",
    "        voxel_out = F.relu(self.voxel_conv1(voxelized_features))\n",
    "        voxel_out = F.relu(self.voxel_conv2(voxel_out))\n",
    "        voxel_out = F.relu(self.voxel_conv3(voxel_out))\n",
    "\n",
    "        # Reshape voxel_out to [B, C, R*R*R] for devoxelization\n",
    "        voxel_out = voxel_out.view(voxel_out.size(0), voxel_out.size(1), -1)\n",
    "\n",
    "        # Devoxelization\n",
    "        point_cloud = trilinear_devoxelize(voxel_out, norm_coords, self.voxelizer.r)\n",
    "\n",
    "        # Set abstraction layers\n",
    "        for sa in self.sa_layers:\n",
    "            point_cloud = sa(point_cloud)\n",
    "\n",
    "        # Flatten and fully connected to produce mu, logvar\n",
    "        point_cloud = point_cloud.view(point_cloud.size(0), -1)\n",
    "        mu = self.fc_mu(point_cloud)\n",
    "        logvar = self.fc_logvar(point_cloud)\n",
    "\n",
    "        # Reparameterization trick to get z\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Store KL divergence for loss computation\n",
    "        self.kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelNetDecoder(nn.Module):\n",
    "    def __init__(self, num_points=2048, latent_size=256, resolution=32, normalize=True, eps=1e-8):\n",
    "        super(VoxelNetDecoder, self).__init__()\n",
    "\n",
    "        # Fully connected layer to expand the latent space\n",
    "        self.fc_expand = nn.Linear(latent_size, 256)  # expand latent size to a suitable dimension\n",
    "        \n",
    "        # Feature Propagation layers\n",
    "        self.fp_blocks = [\n",
    "            ((128, 128), (128, 3, 8)),\n",
    "            ((128, 128), (128, 3, 8)),\n",
    "            ((128, 128), (128, 2, 16)),\n",
    "            ((128, 128, 64), (64, 2, 32))\n",
    "        ]\n",
    "        self.fp_layers = nn.ModuleList([create_fp_module(config) for config in self.fp_blocks])  # assumes a helper function to create fp layers\n",
    "        \n",
    "        # Voxel deconvolution layers\n",
    "        self.voxel_deconv3 = nn.ConvTranspose3d(256, 128, 3, stride=2, padding=1)\n",
    "        self.voxel_deconv2 = nn.ConvTranspose3d(128, 64, 3, stride=2, padding=1)\n",
    "        self.voxel_deconv1 = nn.ConvTranspose3d(64, 1, 3, stride=2, padding=1)  # single channel voxel output\n",
    "        \n",
    "        # Voxelization layer\n",
    "        self.voxelizer = Voxelization(resolution, normalize, eps)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Expand the latent representation\n",
    "        expanded = F.relu(self.fc_expand(z))\n",
    "        \n",
    "        # Reshape it to be processed by FP layers\n",
    "        point_cloud = expanded.view(expanded.size(0), 128, 2)  # assuming 128 features and 2 points\n",
    "        \n",
    "        # Feature propagation layers\n",
    "        for fp in self.fp_layers:\n",
    "            point_cloud = fp(point_cloud)\n",
    "\n",
    "        # Assuming point_cloud is of shape [B, D, N]\n",
    "        features = point_cloud[:, :-3, :]\n",
    "        coords = point_cloud[:, -3:, :]\n",
    "\n",
    "        # Voxelization\n",
    "        voxelized_features, norm_coords = self.voxelizer(features, coords)\n",
    "        \n",
    "        # Voxel deconvolution layers\n",
    "        voxel_out = F.relu(self.voxel_deconv3(voxelized_features))\n",
    "        voxel_out = F.relu(self.voxel_deconv2(voxel_out))\n",
    "        voxel_out = self.voxel_deconv1(voxel_out)  # may need an activation function\n",
    "        \n",
    "        # Reshape voxel_out to [B, C, R*R*R] for devoxelization\n",
    "        voxel_out = voxel_out.view(voxel_out.size(0), voxel_out.size(1), -1)\n",
    "\n",
    "        # Devoxelization\n",
    "        reconstructed_pointcloud = trilinear_devoxelize(voxel_out, norm_coords, self.voxelizer.r)\n",
    "        \n",
    "        return reconstructed_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chamfer_distance(p1, p2):\n",
    "    \"\"\"\n",
    "    Compute the Chamfer Distance between two point clouds.\n",
    "    \n",
    "    Args:\n",
    "    - p1 (torch.Tensor): A tensor of shape (B, N, D) representing a batch of point clouds, each of which has N points of dimension D.\n",
    "    - p2 (torch.Tensor): A tensor of the same shape as p1.\n",
    "    \n",
    "    Returns:\n",
    "    - distance (torch.Tensor): A tensor of shape (B,) representing the Chamfer Distance for each pair of point clouds in the batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the pairwise squared distances between points\n",
    "    # p1 has shape (B, N, D) and p2 has shape (B, M, D)\n",
    "    # The resulting dists will have shape (B, N, M)\n",
    "    dists = torch.sum(p1**2, dim=2).unsqueeze(2) + torch.sum(p2**2, dim=2).unsqueeze(1) - 2 * torch.matmul(p1, p2.permute(0, 2, 1))\n",
    "    \n",
    "    # For each point in p1, find the closest distance in p2\n",
    "    min_dists_p1 = torch.min(dists, dim=2)[0]  # Shape (B, N)\n",
    "    \n",
    "    # For each point in p2, find the closest distance in p1\n",
    "    min_dists_p2 = torch.min(dists, dim=1)[0]  # Shape (B, M)\n",
    "    \n",
    "    # Combine the two distances by taking the average\n",
    "    distance = (torch.sum(min_dists_p1, dim=1) + torch.sum(min_dists_p2, dim=1)) / 2\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudVAE(nn.Module):\n",
    "    def __init__(self, num_points=2048, latent_size=256):\n",
    "        super(PointCloudVAE, self).__init__()\n",
    "        \n",
    "        self.encoder = VariationalVoxelNetEncoder(num_points=num_points, latent_size=latent_size)\n",
    "        self.decoder = VoxelNetDecoder(num_points=num_points, latent_size=latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode input point cloud and get latent variable z\n",
    "        z = self.encoder(x)\n",
    "        \n",
    "        # Decode z to get the reconstructed voxel grid\n",
    "        reconstructed_voxel = self.decoder(z)\n",
    "        \n",
    "        # Convert the reconstructed voxel grid to point cloud\n",
    "        # If the decoder doesn't return a point cloud and instead gives a voxel representation, then you would need a devoxelizer here.\n",
    "        \n",
    "        return reconstructed_voxel, self.encoder.kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The vae_loss function needs to be updated since we won't have mu and logvar separately\n",
    "def vae_loss(reconstructed, original, kl_div, beta=0.0):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = chamfer_distance(reconstructed, original).mean()\n",
    "    \n",
    "    # Return combined loss\n",
    "    return recon_loss + beta * kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "apply() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a VAE\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m vae \u001b[39m=\u001b[39m PointCloudVAE(num_points\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m, latent_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m)\n",
      "\u001b[1;32m/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_points\u001b[39m=\u001b[39m\u001b[39m2048\u001b[39m, latent_size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msuper\u001b[39m(PointCloudVAE, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder \u001b[39m=\u001b[39m VariationalVoxelNetEncoder(num_points\u001b[39m=\u001b[39;49mnum_points, latent_size\u001b[39m=\u001b[39;49mlatent_size)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39m=\u001b[39m VoxelNetDecoder(num_points\u001b[39m=\u001b[39mnum_points, latent_size\u001b[39m=\u001b[39mlatent_size)\n",
      "\u001b[1;32m/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoxel_conv3 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv3d(\u001b[39m128\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Devoxelization layer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevoxelizer \u001b[39m=\u001b[39m trilinear_devoxelize(num_points\u001b[39m=\u001b[39;49mnum_points)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Set abstraction layers (from PVCNN's sa_blocks)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msa_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     ((\u001b[39m32\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m32\u001b[39m), (\u001b[39m1024\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m32\u001b[39m, (\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m))),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     ((\u001b[39m64\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m16\u001b[39m), (\u001b[39m256\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m32\u001b[39m, (\u001b[39m64\u001b[39m, \u001b[39m128\u001b[39m))),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     ((\u001b[39m128\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m), (\u001b[39m64\u001b[39m, \u001b[39m0.4\u001b[39m, \u001b[39m32\u001b[39m, (\u001b[39m128\u001b[39m, \u001b[39m256\u001b[39m))),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     (\u001b[39mNone\u001b[39;00m, (\u001b[39m16\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m32\u001b[39m, (\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-mine/scratch/slurm_tmpdir/2223864/VAE_pointcloud/vae-pv1.ipynb#Y113sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: apply() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "# Create a VAE\n",
    "vae = PointCloudVAE(num_points=2048, latent_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, val_loader, optimizer, epochs=100, device='cuda', print_interval=100):\n",
    "    \"\"\"\n",
    "    Trains the VAE model.\n",
    "    \n",
    "    Args:\n",
    "        model: The VAE model to train.\n",
    "        train_loader: DataLoader for training data.\n",
    "        val_loader: DataLoader for validation data.\n",
    "        optimizer: Optimizer for training.\n",
    "        epochs: Number of epochs for training.\n",
    "        device: Device to move the model to. 'cuda' or 'cpu'.\n",
    "        print_interval: Number of batches after which training loss is printed.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')  # Initialize with a high value\n",
    "\n",
    "    def compute_average_losses(total_loss, total_kl, total_recon, loader_len):\n",
    "        return total_loss / loader_len, total_kl / loader_len, total_recon / loader_len\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, total_kl_div, total_recon_loss = 0, 0, 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            point_clouds = batch['pointcloud'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, kl_div = model(point_clouds)\n",
    "            \n",
    "            recon_loss = chamfer_distance(reconstructed, point_clouds).mean()\n",
    "            combined_loss = vae_loss(reconstructed, point_clouds, kl_div)\n",
    "            \n",
    "            combined_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += combined_loss.item()\n",
    "            total_kl_div += kl_div.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            \n",
    "            if (i+1) % print_interval == 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i+1} - Combined Loss: {combined_loss.item():.4f}, KL Div: {kl_div.item():.4f}, Recon Loss: {recon_loss.item():.4f}\")\n",
    "        \n",
    "        avg_train_loss, avg_train_kl_div, avg_train_recon_loss = compute_average_losses(total_train_loss, total_kl_div, total_recon_loss, len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss, total_val_kl_div, total_val_recon_loss = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                point_clouds = batch['pointcloud'].to(device)\n",
    "                reconstructed, kl_div = model(point_clouds)\n",
    "                \n",
    "                recon_loss = chamfer_distance(reconstructed, point_clouds).mean()\n",
    "                combined_loss = vae_loss(reconstructed, point_clouds, kl_div)\n",
    "                \n",
    "                total_val_loss += combined_loss.item()\n",
    "                total_val_kl_div += kl_div.item()\n",
    "                total_val_recon_loss += recon_loss.item()\n",
    "\n",
    "        avg_val_loss, avg_val_kl_div, avg_val_recon_loss = compute_average_losses(total_val_loss, total_val_kl_div, total_val_recon_loss, len(val_loader))\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch: {epoch+1} Summary:\")\n",
    "        print(f\"Train Avg Combined Loss: {avg_train_loss:.4f}, Train Avg KL Div: {avg_train_kl_div:.4f}, Train Avg Recon Loss: {avg_train_recon_loss:.4f}\")\n",
    "        print(f\"Val Avg Combined Loss: {avg_val_loss:.4f}, Val Avg KL Div: {avg_val_kl_div:.4f}, Val Avg Recon Loss: {avg_val_recon_loss:.4f}\\n\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_vae_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = PointCloudVAE()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001, weight_decay=0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vae(vae, train_loader, val_loader, optimizer,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_vae(model, val_loader, device='cuda'):\n",
    "    \"\"\"\n",
    "    Validates the VAE model and returns the average validation loss.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            point_clouds = batch['pointcloud'].to(device)\n",
    "            reconstructed, kl_div = model(point_clouds)\n",
    "            loss = vae_loss(reconstructed, point_clouds, kl_div)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(model, dataset, num_samples=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Visualize the original and reconstructed point clouds side by side.\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    model.eval()\n",
    "\n",
    "    for idx in indices:\n",
    "        sample = dataset[idx]\n",
    "        points = sample['pointcloud'].unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            reconstructed, _ = model(points)\n",
    "        reconstructed = reconstructed.squeeze(0).cpu().numpy()\n",
    "        points = points.squeeze(0).cpu().numpy()\n",
    "\n",
    "        # Plotting\n",
    "        fig = plt.figure(figsize=(15, 7))\n",
    "        \n",
    "        # Original point cloud\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.scatter(points[:, 0], points[:, 1], points[:, 2], s=5)\n",
    "        ax1.set_title(\"Original\")\n",
    "        \n",
    "        # Reconstructed point cloud\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.scatter(reconstructed[:, 0], reconstructed[:, 1], reconstructed[:, 2], s=5)\n",
    "        ax2.set_title(\"Reconstructed\")\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstruction(vae, val_dset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_vae(model, num_samples=5, latent_dim=256, device='cuda'):\n",
    "    \"\"\"\n",
    "    Samples point clouds from the VAE model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        #\n",
    "        z_sampled = torch.randn(num_samples, latent_dim).to(device)\n",
    "        generated_point_clouds = model.decoder(z_sampled)\n",
    "    return generated_point_clouds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_generated_point_clouds(model, num_samples=5, latent_dim=256, device='cuda'):\n",
    "    \"\"\"\n",
    "    Visualizes point clouds generated from the VAE.\n",
    "    \"\"\"\n",
    "    generated_point_clouds = sample_from_vae(model, num_samples, latent_dim, device)\n",
    "    for i in range(num_samples):\n",
    "        points = generated_point_clouds[i].cpu().numpy()\n",
    "\n",
    "        # Plotting\n",
    "        fig = plt.figure(figsize=(7, 7))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=5)\n",
    "        ax.set_title(f\"Generated Point Cloud {i+1}\")\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_generated_point_clouds(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
